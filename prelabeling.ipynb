{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "from scipy.stats.kde import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.classes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "image_folder = \"insecam_parser/1005423\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [os.path.join(image_folder, i) for i in os.listdir(image_folder)]\n",
    "img = cv2.imread(imgs[0])\n",
    "h, w, c = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_raw = [model(imgs[i:i+batch_size]) for i in range(0, len(imgs), batch_size)]\n",
    "results = [torch.cat(i.xyxy, dim=0) for i in results_raw]\n",
    "results = torch.cat(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_boxes = results[:, :4].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_boxes = [] \n",
    "persons_cropped = []\n",
    "for i in results_raw:\n",
    "    crop_results = i.crop(save=False)\n",
    "    for j in crop_results:\n",
    "        person_boxes.append(torch.stack(j['box'], dim=0).cpu().numpy())\n",
    "        persons_cropped.append(j['im'])\n",
    "person_boxes = np.array(person_boxes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all predictions\n",
    "%matplotlib inline\n",
    "centers = np.apply_along_axis((lambda x: (((x[2] + x[0]) / 2), ((x[3] + x[1]) / 2))), 1, person_boxes) \n",
    "for point in centers:\n",
    "    img = cv2.circle(img, (int(point[0]), int(point[1])), radius=4, color=(0, 0, 255), thickness=-1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imgs[0])\n",
    "m1 = centers[:, 0]\n",
    "m2 = img.shape[0] - centers[:, 1]\n",
    "xmin = m1.min()\n",
    "xmax = m1.max()\n",
    "ymin = m2.min()\n",
    "ymax = m2.max()\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "values = np.vstack([m1, m2])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X.shape)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_dpi(100)\n",
    "ax.imshow(np.rot90(Z), cmap=plt.cm.cubehelix,\n",
    "          extent=[xmin, xmax, ymin, ymax], alpha=0.9)\n",
    "ax.imshow(im, extent=[x.min(), x.max(), y.min(), y.max()], aspect='auto', alpha=0.15)\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    landmark1 = ((landmark1.x), (landmark1.y), (landmark1.z))\n",
    "    landmark2 = ((landmark2.x), (landmark2.y), (landmark2.z))\n",
    "    landmark3 = ((landmark3.x), (landmark3.y), (landmark3.z))\n",
    "    ba = np.array(landmark1) - np.array(landmark2)\n",
    "    bc = np.array(landmark3) - np.array(landmark2)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def classifyPose(landmarks, output_image, display=True):\n",
    "    label = 'Unknown Pose'\n",
    "    color = (0, 0, 255)\n",
    "    if landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility < 0.5 or \\\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].visibility < 0.5 or \\\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].visibility < 0.5:\n",
    "        left_side_angle = 0\n",
    "    else:\n",
    "        left_side_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "    if landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].visibility < 0.5 or \\\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].visibility < 0.5 or \\\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].visibility < 0.5:\n",
    "        right_side_angle = 0\n",
    "    else:\n",
    "        right_side_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "    if 50 < left_side_angle < 110 or 50 < right_side_angle < 110:\n",
    "        label = \"Sitting\"\n",
    "    elif 155 < left_side_angle < 215 or 155 < right_side_angle < 215:\n",
    "        label = \"Standing\"\n",
    "    if label != 'Unknown Pose':\n",
    "        color = (0, 255, 0)  \n",
    "    cv2.putText(output_image, label, (0, 10),cv2.FONT_HERSHEY_PLAIN, 1, color, 1)\n",
    "    if display:\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1])\n",
    "        plt.title(\"Output Image\");\n",
    "        plt.axis('off');  \n",
    "        plt.show()\n",
    "    else:\n",
    "        return output_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "box_labels = []\n",
    "labeled_images = []\n",
    "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.4, model_complexity=1) as pose:\n",
    "    for image in persons_cropped:\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        image_height, image_width, _ = image.shape\n",
    "        if not results.pose_landmarks:\n",
    "            box_labels.append(\"Unknown Pose\")\n",
    "            continue\n",
    "        # Draw pose landmarks.\n",
    "        annotated_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).copy()\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        \n",
    "        im, label = classifyPose(results.pose_landmarks.landmark, annotated_image, display=False)\n",
    "        box_labels.append(label)\n",
    "        labeled_images.append(im)\n",
    "        '''\n",
    "        if label == \"Sitting\":\n",
    "            classifyPose(results.pose_landmarks.landmark, annotated_image, display=True)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.choice(len(labeled_images), 5):\n",
    "    plt.imshow(labeled_images[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=15, min_samples=10).fit(centers)\n",
    "# get centroids\n",
    "centroids = []\n",
    "standing_counts = []\n",
    "sitting_counts = []\n",
    "cluster_sizes = []\n",
    "img = cv2.imread(imgs[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "box_labels = np.array(box_labels)\n",
    "for i in np.unique(clustering.labels_):\n",
    "    if i == -1:\n",
    "        continue\n",
    "    box_labels_cluster = box_labels[clustering.labels_==i]\n",
    "    standing_count = np.count_nonzero(box_labels_cluster == \"Standing\")\n",
    "    sitting_count = np.count_nonzero(box_labels_cluster == \"Sitting\")\n",
    "    standing_counts.append(standing_count)\n",
    "    sitting_counts.append(sitting_count)\n",
    "    cluster_sizes.append(box_labels_cluster.shape[0])\n",
    "    points_of_cluster = centers[clustering.labels_==i,:]\n",
    "    center_point = np.mean(points_of_cluster, axis=0)\n",
    "    centroids.append(center_point)\n",
    "    \n",
    "standing_counts = np.array(standing_counts)\n",
    "#standing_counts = standing_counts / np.max(standing_counts)\n",
    "# draw centroids\n",
    "for i, point in enumerate(centroids):\n",
    "    img = cv2.circle(img, (int(point[0]), int(point[1])), radius=8, color=(255, 0, 0), thickness=-1)\n",
    "    cv2.putText(img, \"{},{}\".format(standing_counts[i], sitting_counts[i]).format(), point.astype(int), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(19, 10))\n",
    "ax.axis('off')\n",
    "ax.imshow(img, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in np.unique(clustering.labels_):\n",
    "    if i == -1:\n",
    "        continue\n",
    "    indices = np.where(clustering.labels_ == i)\n",
    "    cluster_boxes = person_boxes[indices]\n",
    "    wh = np.apply_along_axis((lambda x: (((x[2] - x[0])), ((x[3] - x[1])))), 1, cluster_boxes) \n",
    "    means.append(np.mean(wh, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw mean boxes around centroids\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "img = cv2.imread(imgs[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cmap = matplotlib.cm.get_cmap('hsv')\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=len(means))\n",
    "counter = 0\n",
    "for centr, wh in zip(centroids, means):\n",
    "    p1 = (int(centr[0] - wh[0] / 2), int(centr[1] - wh[1] / 2))\n",
    "    p2 = (int(centr[0] + wh[0] / 2), int(centr[1] + wh[1] / 2))\n",
    "    color = cmap(norm(counter), bytes=True)[:3]\n",
    "    img = cv2.rectangle(img, p1, p2, color=tuple(int(x) for x in color), thickness=3)\n",
    "    counter += 1\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c29894e933a266f5c6a79e8102730a7bbddf08d710a5272010749372da075b61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
